{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Logistic Regression as a NN",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7oY_p_ziMIj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import h5py\n",
        "from scipy.special import xlogy\n",
        "\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrWXdcYKQaev",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_dataset():\n",
        "\n",
        "  \"\"\"Loads the Cat vs Non-Cat dataset\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  X_train, y_train, X_test, y_test, classes: Arrays\n",
        "    Dataset splitted into train and test with classes\n",
        "  \"\"\"\n",
        "\n",
        "  train_dataset = h5py.File('datasets/train_catvnoncat.h5', \"r\")\n",
        "  train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:])\n",
        "  train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:])\n",
        "\n",
        "  test_dataset = h5py.File('datasets/test_catvnoncat.h5', \"r\")\n",
        "  test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:])\n",
        "  test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:])\n",
        "\n",
        "  classes = np.array(test_dataset[\"list_classes\"][:])\n",
        "  \n",
        "  return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxuKKQKHsl1d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(Z):\n",
        "  \n",
        "  \"\"\"Applies sigmoid function to an array/value\n",
        "\n",
        "    Arguments\n",
        "    ---------\n",
        "    Z: float/int/array_like\n",
        "      Original Value\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    A: same shape as input\n",
        "      Value after applying sigmoid function\n",
        "  \"\"\"\n",
        "  return 1/(1+np.power(np.e, -Z))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KufR7hEgF4Wu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid_prime(Z):\n",
        "  \n",
        "  \"\"\"Applies differentiation of sigmoid function to an array/value\n",
        "\n",
        "    Arguments\n",
        "    ---------\n",
        "    Z: float/int/array_like\n",
        "      Original Value\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    A: same shape as input\n",
        "      Value after applying diff of sigmoid function\n",
        "  \"\"\"\n",
        "  return (1-np.power(Z, 2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqQmUi_jldca",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialize_nn(X):\n",
        "\n",
        "  \"\"\"Initializes random weights and bias\n",
        "\n",
        "  Arguments\n",
        "  ---------\n",
        "  X: array-like\n",
        "    Train Dataset\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  dict\n",
        "    Contains the randomly initialized weights and bias arrays where-\n",
        "    shape(weights) = (X.Shape[0], 1)\n",
        "    bias = float value\n",
        "\n",
        "    The keys for weights and bias arrays in the dict is 'w' and 'b'\n",
        "  \"\"\"\n",
        "\n",
        "  np.random.seed(999)\n",
        "\n",
        "  w = np.random.randn(X.shape[1], 1) * 0.01\n",
        "  b = 0\n",
        "\n",
        "  return {'w': w, 'b': b}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgAUvZPAldZx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward_prop(X, params):\n",
        "\n",
        "  \"\"\"Performs forward propagation and calculates output value\n",
        "\n",
        "    Arguments\n",
        "    ---------\n",
        "    X: array_like\n",
        "      Data\n",
        "    params: dictionary\n",
        "      Parameter dict contaning 'w' and 'b'\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    dict\n",
        "      Dictionary contaning 'z' and 'a'\n",
        "  \"\"\"\n",
        "\n",
        "  w = params['w']\n",
        "  b = params['b']\n",
        "\n",
        "  z = np.dot(X, w) + b\n",
        "  a = sigmoid(z)\n",
        "  \n",
        "  return {'z': z, 'a': a}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtVGSvEUldXO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def backward_prop(X, y, cache):\n",
        "\n",
        "  \"\"\"Performs forward propagation and calculates output value for a layer\n",
        "\n",
        "    Arguments\n",
        "    ---------\n",
        "    X: array_like\n",
        "      Data\n",
        "    y: array_like\n",
        "      True labels\n",
        "    cache: dictionary\n",
        "      Dictionary containing 'z' and 'a'\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    dict\n",
        "      Dictionary containing gradients 'dz', 'dw' and 'db'\n",
        "  \"\"\"\n",
        "\n",
        "  z = cache['z']\n",
        "  a = cache['a']\n",
        "  m = X.shape[0]\n",
        "\n",
        "  dz = a - y\n",
        "  dw = (1./m)*np.dot(X.T, dz)\n",
        "  db = (1./m)*np.sum(dz)\n",
        "\n",
        "  return {'dz': dz, 'dw': dw, 'db': db}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PukmFEXgo0Lp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def update_weights(params, changes, learning_rate=0.01):\n",
        "\n",
        "  \"\"\"Performs forward propagation and calculates output value for a layer\n",
        "\n",
        "    Arguments\n",
        "    ---------\n",
        "    params: dict\n",
        "      Dictionary containing 'w' and 'b'\n",
        "    changes: dict\n",
        "      Dictionary containing 'dw' and 'db'\n",
        "    learning_rate: int, float\n",
        "      Learning rate for the weight update\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    dict\n",
        "      Dictionary containing updated weights and biases\n",
        "\n",
        "      The keys for weights and bias arrays in the dict is 'w' and 'b'\n",
        "  \"\"\"\n",
        "\n",
        "  w = params['w']\n",
        "  b = params['b']\n",
        "  dw = changes['dw']\n",
        "  db = changes['db']\n",
        "\n",
        "  w -= learning_rate*dw\n",
        "  b -= learning_rate*db\n",
        "\n",
        "  return {'w': w, 'b': b}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ktd0xy3Xo0B5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_loss(cache, y):\n",
        "\n",
        "  \"\"\"Calculate the entropy loss\n",
        "\n",
        "    Arguments\n",
        "    ---------\n",
        "    cache: dict\n",
        "      Dictionary contaning 'z' and 'a'\n",
        "      y: array-like\n",
        "        True lables\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    loss: float\n",
        "      Entropy loss\n",
        "  \"\"\"\n",
        "\n",
        "  a = cache['a']\n",
        "  m = y.shape[0]\n",
        "\n",
        "  return -1/m*np.sum(xlogy(y, a) + xlogy(1-y, 1-a))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7DR0NAnik4S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, y_train, X_test, y_test, classes = load_dataset()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1GVDFo0bhBD",
        "colab_type": "code",
        "outputId": "766841a1-920b-45d6-f9be-4f9cb1af0908",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(209, 64, 64, 3)\n",
            "(209,)\n",
            "(50, 64, 64, 3)\n",
            "(50,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4ZN8BcKldUs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], -1)/255.\n",
        "X_test = X_test.reshape(X_test.shape[0], -1)/255.\n",
        "y_train = y_train.reshape(-1, 1)\n",
        "y_test = y_test.reshape(-1, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P99C_DDmUsN3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 1000\n",
        "learning_rate = 5e-3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_q0usp4gzQuy",
        "colab_type": "code",
        "outputId": "288cf610-e25c-46dd-d20e-d3342ddce28c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "params = initialize_nn(X_train)\n",
        "\n",
        "for i in range(epochs):\n",
        "  cache = forward_prop(X_train, params)\n",
        "  loss = calculate_loss(cache, y_train)\n",
        "  updates = backward_prop(X_train, y_train, cache)\n",
        "  params = update_weights(params, updates, learning_rate=learning_rate)\n",
        "\n",
        "  if i%(epochs/10) == 0:\n",
        "    print('Epoch: {}\\tLoss:{:.5f}'.format(i, loss), end='')\n",
        "    train_cache = np.where(cache['a']>0.5, 1, 0)\n",
        "    print('\\tTraining accuracy:{:.5f}'.format(accuracy_score(y_train, train_cache)), end='')\n",
        "    test_cache = forward_prop(X_test, params)['a']\n",
        "    test_cache = np.where(test_cache>=0.5, 1, 0)\n",
        "    print('\\tTesting accuracy:{:.5f}'.format(accuracy_score(y_test, test_cache)))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0\tLoss:0.72463\tTraining accuracy:0.45455\tTesting accuracy:0.34000\n",
            "Epoch: 100\tLoss:0.58224\tTraining accuracy:0.68421\tTesting accuracy:0.34000\n",
            "Epoch: 200\tLoss:0.46335\tTraining accuracy:0.81818\tTesting accuracy:0.44000\n",
            "Epoch: 300\tLoss:0.37246\tTraining accuracy:0.89952\tTesting accuracy:0.62000\n",
            "Epoch: 400\tLoss:0.32947\tTraining accuracy:0.91866\tTesting accuracy:0.70000\n",
            "Epoch: 500\tLoss:0.30155\tTraining accuracy:0.92823\tTesting accuracy:0.72000\n",
            "Epoch: 600\tLoss:0.27835\tTraining accuracy:0.93780\tTesting accuracy:0.74000\n",
            "Epoch: 700\tLoss:0.25866\tTraining accuracy:0.94258\tTesting accuracy:0.74000\n",
            "Epoch: 800\tLoss:0.24167\tTraining accuracy:0.95694\tTesting accuracy:0.74000\n",
            "Epoch: 900\tLoss:0.22683\tTraining accuracy:0.96172\tTesting accuracy:0.76000\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}